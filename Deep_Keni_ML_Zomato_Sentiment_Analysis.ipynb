{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "U2RJ9gkRphqQ",
        "x-EpHcCOp1ci",
        "n3dbpmDWp1ck",
        "Ag9LCva-p1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "crA5lg2OG5gR",
        "0nCyNikATcuL",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Member**          - Deep Keni\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on analyzing restaurant reviews and related information to understand what factors influence customer ratings and how textual feedback can be used to build predictive machine learning models. The dataset contains structured attributes such as cost, cuisines count, whether pictures are available, operating hours, reviewer activity, and timestamps, along with unstructured text in the form of customer reviews. The main objective was to clean the data, extract useful features from both text and numerical columns, explore relationships in the data, and prepare a complete pipeline that can be used for machine learning models.\n",
        "\n",
        "The first phase involved understanding the dataset and performing data cleaning. Missing values, inconsistent formats, and unnecessary columns were handled. Text reviews were preprocessed using standard NLP steps such as expanding contractions, converting text to lowercase, removing punctuation, URLs, digits, stopwords, and extra spaces. Tokenization and lemmatization were applied to normalize the text and reduce vocabulary size. These steps helped convert informal user reviews into a consistent and machine-friendly format.\n",
        "\n",
        "Feature engineering played an important role in this project. Temporal features were extracted from the review timestamp such as year, month, day of the week, and hour to capture time-based patterns in customer behavior. A review length feature was created to represent how detailed a review is. Numeric variables like cost and reviewer activity metrics were transformed using log transformation to reduce skewness and the effect of extreme values. Feature selection was done using domain understanding by removing identifiers and redundant columns such as raw timestamps, and intermediate NLP artifacts once vectorization was complete. This helped reduce noise and avoid data leakage.\n",
        "\n",
        "For text representation, TF-IDF vectorization was used to convert reviews into numerical features. This method captures the importance of words across documents and reduces the impact of commonly occurring terms. Since TF-IDF produces high-dimensional sparse features, dimensionality reduction using TruncatedSVD was explored as an optional optimization step to reduce dimensionality, improve computational efficiency, and potentially improve model performance for clustering and distance-based models. Numerical features were standardized using StandardScaler to bring them onto a comparable scale for models sensitive to feature magnitude, while binary indicators and TF-IDF features were handled appropriately.\n",
        "\n",
        "Basic hypothesis testing was performed to gain business insights from the data. Simple statistical tests were used to examine whether restaurants with pictures receive different ratings, whether cost is related to ratings, and whether 24-hour operation impacts customer ratings. These tests were exploratory and helped understand relationships in the data. However, hypothesis testing was not directly used in training machine learning models and was treated as an insight-generation step.\n",
        "\n",
        "Finally, the data was split into training and testing sets to ensure fair evaluation of machine learning models on unseen data. The overall pipeline prepares the dataset for building regression, classification, and clustering models. The project emphasizes building a clean, end-to-end workflow that includes preprocessing, feature engineering, vectorization, scaling, and optional dimensionality reduction. The results and insights from this project can help businesses understand customer feedback better, identify factors that influence ratings, and build data-driven strategies to improve customer experience and engagement."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Deep-keni"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze Zomato restaurant data to help customers find good restaurants and help Zomato understand their business better.**\n",
        "> The main problem is to clean and prepare this data and then analyze it to find useful patterns and insights.\n",
        "The project aims to:\n",
        "\n",
        "* Clean and preprocess the dataset\n",
        "\n",
        "* Explore relationships between cost, ratings, cuisines, and reviews\n",
        "\n",
        "* Group similar restaurants using clustering techniques\n",
        "\n",
        "* Analyze customer sentiment from review text\n",
        "\n",
        "* Convert the analysis into meaningful business insights\n",
        "\n",
        "The objective is to support customers in finding better restaurants and help the company identify areas of improvement."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Pls follow this or error will come during runnig all cells text*\n",
        "Go to Let's Begin -> Know Your Data -> Import Libraries -> Upload files manually\n",
        "( in 3rd cell of import libraries )"
      ],
      "metadata": {
        "id": "PV6d6zz9ZcyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installed requirements\n",
        "!pip install textblob wordcloud\n",
        "!pip install contractions"
      ],
      "metadata": {
        "collapsed": true,
        "id": "19HdEIp_Zqam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from google.colab import files\n",
        "import contractions\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "id": "mcMO4-T-Y1cg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#files uploaded\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loaded datasets\n",
        "restaurant_df = pd.read_csv('Zomato Restaurant names and Metadata.csv')\n",
        "review_df = pd.read_csv('Zomato Restaurant reviews.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "restaurant_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3VTCGXFTaoyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_df.shape"
      ],
      "metadata": {
        "id": "QewHIJy90rpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.shape"
      ],
      "metadata": {
        "id": "H_E5s_W5bm83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information\n",
        "\n"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging both datasets\n",
        "merged_data = review_df.merge(\n",
        "        restaurant_df,\n",
        "        left_on='Restaurant',      # Column from reviews dataset\n",
        "        right_on='Name',           # Column from restaurants dataset\n",
        "        how='left',                # Keep all reviews, match restaurant info\n",
        ")"
      ],
      "metadata": {
        "id": "gZrW2oUilp4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coverting the datatypes of required columns from object to the specific ones(eg.int, datetime)\n",
        "cols_to_int = ['Rating','Pictures','Cost']\n",
        "merged_data[cols_to_int] = merged_data[cols_to_int].apply(pd.to_numeric, errors='coerce')        #converted obj to float\n",
        "merged_data['Time'] = merged_data['Time'].apply(pd.to_datetime , errors = 'coerce')              #coverted obj to datetime"
      ],
      "metadata": {
        "id": "CbNcmY2hto2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract numbers from Metadata (e.g. 4 Reviews, 32 Followers)\n",
        "merged_data['Reviewer_Review_Count'] = (\n",
        "    merged_data['Metadata']\n",
        "    .str.extract(r'(\\d+)\\s*Reviews?', expand=False)\n",
        "    .fillna(0)\n",
        "    .astype('int')\n",
        ")\n",
        "\n",
        "merged_data['Reviewer_Followers'] = (\n",
        "    merged_data['Metadata']\n",
        "    .str.extract(r'(\\d+)\\s*Followers?', expand=False)\n",
        "    .fillna(0)\n",
        "    .astype('int')\n",
        ")\n",
        "\n",
        "#converting the pictures column to boolean form\n",
        "merged_data['Has_Pictures'] = (merged_data['Pictures'].fillna(0)>0).astype(bool)"
      ],
      "metadata": {
        "id": "rW_hwFwZ7A8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the unnecessary columns which are not required in predictions\n",
        "merged_data = merged_data.drop(columns=['Reviewer','Links','Pictures','Metadata'] , errors='ignore')"
      ],
      "metadata": {
        "id": "cXVsGzX108pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = merged_data[['Restaurant','Review','Rating','Time','Reviewer_Review_Count',\n",
        "                          'Reviewer_Followers','Has_Pictures','Cost','Cuisines','Collections','Timings',]]"
      ],
      "metadata": {
        "id": "HMdp5y2sI91k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1PcRczLWs0bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count"
      ],
      "metadata": {
        "id": "BmISh8OHX3Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data_backup = merged_data.copy()               #just saved the copy of the original dataframe for safety"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#as there are many duplicates in the dataframe we remove all by only keeping the first occurance .\n",
        "merged_data = merged_data.drop_duplicates(keep='first')"
      ],
      "metadata": {
        "id": "q-iIHC-QW7Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.duplicated().any()                   #checks finally whether any duplicates still there or not"
      ],
      "metadata": {
        "id": "5mql6dHZXdLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.shape                             # 10000 rows reduced to 9964 : redundant rows removed"
      ],
      "metadata": {
        "id": "xIL1ykwRX3gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the missing values : specified rows have null values in the respective columns\n",
        "merged_data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NVwbCD9kZCPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculates the missing values but in % format\n",
        "(merged_data.isnull().sum() / len(merged_data)) * 100"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5hroyvXwZCAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(merged_data.isnull(), cbar=False, yticklabels=False)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Rows\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jaGK_gv2cBST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#why this map was choosen ?\n",
        "'''To visually inspect the pattern and distribution of missing values across different features and rows.'''\n",
        "\n",
        "#insight(s) ?\n",
        "'''Missing values are primarily concentrated in the Cost and Collections columns, while most other features\n",
        "have minimal or no missing values, indicating feature-specific data gaps rather than random missingness.'''\n",
        "\n",
        "#Business impact ?\n",
        "'''Incomplete cost and collection information can reduce recommendation accuracy and clustering reliability,\n",
        "highlighting the need for better data collection or careful imputation strategies to avoid biased business insights.'''"
      ],
      "metadata": {
        "id": "e5sn54tocBPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_counts = merged_data.isnull().sum()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(missing_counts.index, missing_counts.values)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Missing Values Count by Column\")\n",
        "plt.ylabel(\"Number of Missing Values\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.tight_layout()\n",
        "plt.show();\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kv8a5s9tcBL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#why this map was choosen ?\n",
        "'''To compare the extent of missing values across different features and identify columns with the highest data quality issues.'''\n",
        "\n",
        "#insight(s) ?\n",
        "'''The Cost and Collections columns have significantly higher missing values compared to other features, whereas core features like\n",
        "Rating, Cuisines, and Review are largely complete.'''\n",
        "\n",
        "#Business impact ?\n",
        "'''High missingness in pricing and categorization data may weaken customer decision-making and segmentation accuracy. Improving data\n",
        " completeness in these areas can enhance user experience and business recommendations.'''"
      ],
      "metadata": {
        "id": "2U4X9x2NcBC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "B9wRBuXW0Hdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling missing values\n",
        "\n",
        "#text column\n",
        "merged_data['Review'] = merged_data['Review'].fillna('')\n",
        "\n",
        "#numeric columns: used medians to avoid skew from outliers\n",
        "merged_data['Rating'] = merged_data['Rating'].fillna(merged_data['Rating'].median())\n",
        "merged_data['Cost'] = merged_data['Cost'].fillna(merged_data['Cost'].median())\n",
        "\n",
        "#engineered numeric features (if any NaNs remain)\n",
        "merged_data['Reviewer_Review_Count'] = merged_data['Reviewer_Review_Count'].fillna(merged_data['Reviewer_Review_Count'].median())\n",
        "merged_data['Reviewer_Followers'] = merged_data['Reviewer_Followers'].fillna(merged_data['Reviewer_Followers'].median())\n",
        "\n",
        "#categorical columns\n",
        "merged_data['Collections'] = merged_data['Collections'].fillna('Unknown')\n",
        "merged_data['Timings'] = merged_data['Timings'].fillna('Not Available')"
      ],
      "metadata": {
        "id": "KoDAxKZW0HSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropped 2 \"Time\" rows which were leading to inconsistency of data flow as they were left unfilled\n",
        "merged_data = merged_data.dropna(subset=['Time'])"
      ],
      "metadata": {
        "id": "UuFEbpTP0HGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#successfully removed all null values from the table and now all rows are filled with values\n",
        "merged_data.isnull().sum()"
      ],
      "metadata": {
        "id": "H35JoTT30G4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I analyzed Zomato restaurant and review data to understand customer preferences and restaurant patterns . The main goal was to clean the data, explore relationships between different features like cost, ratings, cuisines, and reviews .\n",
        "\n",
        "This project helps in:\n",
        "* Finding patterns in customer ratings and costs\n",
        "* Understanding which cuisines and collections are popular\n",
        "* Grouping restaurants into meaningful segments\n",
        "* Understanding customer opinions from review text"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.columns"
      ],
      "metadata": {
        "id": "F6TdJMfiReug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the dataset basically contains 11 columns which features the restaurent , reviews , cuisines ,timings data & metadata .\n",
        "'''\n",
        "1) Restaurant column indicates the name of the restaurant .\n",
        "2) Review , Rating and Time columns indiacte the review , rating given to the respective restaurant and at what time .\n",
        "3) Reviewer_Review_Count and Reviewer_Followers indicate how active and influential the reviewer is .\n",
        "4) Has_Pictures shows whether reviewer uploaded the images of the restaurant's .\n",
        "5) Cost indicates the average dining cost at the restaurant .\n",
        "6) Cuisines and Collections show what type of food the restaurant provides and whats the quality they provide for their customers .\n",
        "7) Timings for the restaurant indicates when the restaurant is open and on which days .\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eNowQLEsarGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1) Columns like Reviewer_Review_Count and Reviewer_Followers are in integer format .\n",
        "2) Has_Pictures is treated as a boolean feature since only the presence of images matters, not the number of images .\n",
        "3) Time is converted to proper datetime format to extract the trend of reviews over time .\n",
        "4) The cost ranges from a min of Rs.100 to max of Rs.900 with an average of about Rs.550 for the list of restaurants.\n",
        "5) Around 38.8% of values from the rating column are 5.0 rated , shows a positive bias in reviews .\n",
        "6) Most cuisines are widely covered across restaurants, indicating diverse food options.\n",
        "7) Mostly all restaurants are open on all weekdays and provide service during the daytime as well as nighttime .\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "02bjbop3T_gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Restaurant**\n",
        "* Categorical data (text) .\n",
        "* Represents the name of the restaurant .\n",
        "* Examples : Mathura Vilas , Beyond the Flavours , Karachi Cafe , Chocolate Room , etc .\n",
        "* There are same restaurants multiple times which after grouping can give\n",
        "  useful information about the restaurent-wise performance and ratings .\n",
        "\n",
        "####**Review**\n",
        "* Text form data .\n",
        "* It contains the reviews which are given by the customers .\n",
        "* This data is the most useful part for sentiment analysis .\n",
        "\n",
        "####**Rating**\n",
        "* Numeric float data .\n",
        "* The ratings are given by the customers ranging from 0.0 to 5.0 .\n",
        "* Indicates whether the customer is satisfied or not after vising the restaurants .\n",
        "\n",
        "####**Time**\n",
        "* DateTime .\n",
        "* We can extract the following things from the datetime :\n",
        "    * Date\n",
        "    * Day\n",
        "    * Hour\n",
        "    * Trends by time\n",
        "* This data can provide insights about customer behavior and restaurant activity patterns over time .\n",
        "\n",
        "####**Reviewer_Review_Count**\n",
        "* Numeric values .\n",
        "* Shows how many reviews a reviewer has given.\n",
        "* Indicates the experience level of the reviewer.\n",
        "* Can help distinguish between trusted/experienced reviewers and new reviewers.\n",
        "\n",
        "####**Reviewer_Followers**\n",
        "* Type: Numeric\n",
        "* Proxy for reviewer influence.\n",
        "* Reviewers with more followers may have higher impact on public opinion.\n",
        "\n",
        "####**Has_Pictures**\n",
        "* Binary (0/1) .\n",
        "* 0 indicates no pictures of the restaurants are available and 1 shows that images are present .\n",
        "* Represents whether the reviewer uploaded images of the restaurant.\n",
        "* Acts as an engagement indicator and may influence customer trust.\n",
        "\n",
        "####**Cost**\n",
        "* Type: Numeric\n",
        "* Represents the average cost of dining at the respective restaurant .\n",
        "* It shows the cost for utmost two people on an average .\n",
        "* Cost can be related to reviews and rating too .\n",
        "\n",
        "####**Cuisines**\n",
        "* Multi-category text data.\n",
        "* Can later be split into multiple cuisine labels since the same restaurant can offer multiple cuisines.\n",
        "* Useful for cuisine popularity analysis, which helps identify which cuisines are most liked and highly rated by customers.\n",
        "\n",
        "####**Collections**\n",
        "* Categorical data.\n",
        "* Meaning: Special lists or curated collections in which a restaurant is featured.\n",
        "* Useful for:\n",
        "    * Understanding quality tags\n",
        "    * Identifying restaurants promoted or curated by the platform\n",
        "\n",
        "####**Timings**\n",
        "* Text data.\n",
        "* Can be parsed later into opening and closing times.\n",
        "* Useful for operational analysis (e.g., opening hours vs customer activity)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking unique values for each column, it was observed that:\n",
        "* Numeric columns such as Rating, Cost, Reviewer_Review_Count, and Reviewer_Followers contain valid ranges and no abnormal values.\n",
        "* Has_Pictures is binary (0/1) and is clean.\n",
        "* Restaurant names appear multiple times, which is expected due to multiple reviews per restaurant.\n",
        "* Cuisines and Collections contain multiple values in a single cell separated by commas, which will require splitting and normalization during data wrangling.\n",
        "* Timings contain inconsistent text formats for opening and closing hours, which will need parsing and standardization later.\n",
        "\n",
        "This confirms that while numeric features are clean, text-based categorical features require preprocessing before analysis."
      ],
      "metadata": {
        "id": "jyr3LumB2AHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling restaurant col\n",
        "merged_data['Restaurant'] = (\n",
        "    merged_data['Restaurant']\n",
        "    .str.replace(r'\\.{2,}', '', regex=True)   #removes multiple dots like ...\n",
        "    .str.replace('#', '', regex=False)        #remove #\n",
        "    .str.replace(r'\\s+', ' ', regex=True)     #remove spaces\n",
        "    .str.strip()\n",
        ")\n"
      ],
      "metadata": {
        "id": "mNCXXjAG48jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now proceed with cleaning and transforming the 'Cuisines' column\n",
        "merged_data['Cuisines'] = (\n",
        "    merged_data['Cuisines']\n",
        "    .str.replace('-', ' ', regex=False)       # - replaced with 'space'\n",
        "    .str.replace('&', 'and', regex=False)     # & replaced with and\n",
        "    .str.replace(r'\\s+', ' ', regex=True)\n",
        "    .str.strip()\n",
        "    .str.title()                              #standardized the case char's\n",
        "    .str.split(',')                           #splitted the colms into list format to count the no of cuisines in each restauarant\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dy8LM0q9JjQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added one required column after cleaning cuisines col\n",
        "merged_data['Cuisines_Count'] = merged_data['Cuisines'].apply(len)"
      ],
      "metadata": {
        "id": "WgxHc07khgNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling collections col\n",
        "merged_data['Collections'] = (\n",
        "    merged_data['Collections']\n",
        "    .str.replace('#', '', regex=False)        #removed hashtags\n",
        "    .str.replace(r'\\.', ' ', regex=True)      #replaced dots with 'space'\n",
        "    .str.replace('-', ' ', regex=False)       #replaced hyphen with 'space'\n",
        "    .str.replace(r'\\s+', ' ', regex=True)     #removed multiple spaces\n",
        "    .str.strip()\n",
        ")"
      ],
      "metadata": {
        "id": "xTVSzVbsJjLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling timings col\n",
        "merged_data['Timings'] = (\n",
        "    merged_data['Timings']\n",
        "    .str.replace(r'\\s+', ' ', regex=True)     #only removed spaces rest every char is importamt\n",
        "    .str.strip()\n",
        ")\n"
      ],
      "metadata": {
        "id": "5jmlDBuoJjCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding required col wwhich have data extracted from date\n",
        "merged_data['Is_Open_All_Days'] = merged_data['Timings'].str.contains(r'Mon-Sun|All Days|Everyday|Daily', case=False, regex=True).astype(bool)\n",
        "merged_data['Is_24_Hours'] = merged_data['Timings'].str.contains(r'24 Hours|24/7|Open 24 Hours', case=False, regex=True).astype(bool)"
      ],
      "metadata": {
        "id": "fpvz9hVZp4Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordered_cols = ['Restaurant','Review','Rating','Time','Reviewer_Review_Count','Reviewer_Followers','Has_Pictures','Cost',\n",
        "                'Cuisines','Cuisines_Count','Collections','Timings','Is_Open_All_Days','Is_24_Hours'\n",
        "]\n",
        "\n",
        "merged_data = merged_data[ordered_cols]\n"
      ],
      "metadata": {
        "id": "KtcH98bxY0BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the data wrangling phase, the dataset was cleaned and structured to make it analysis-ready. The Restaurant column was cleaned by removing decorative characters such as multiple dots and hashtags, and extra spaces were normalized to avoid duplicate names caused by formatting differences.\n",
        "\n",
        "The Cuisines column was standardized by replacing hyphens with spaces, converting ‘&’ to ‘and’, normalizing spacing, and standardizing text case. Since multiple cuisines can appear in a single cell, the values were converted into lists, and a new feature Cuisines_Count was created to capture the number of cuisines offered by each restaurant. This helps analyze whether cuisine variety has any relation to ratings or customer interest.\n",
        "\n",
        "The Collections column was cleaned by removing unnecessary symbols and extra spaces. As a large number of values were missing and filled with “Unknown”, no additional features were derived from this column to avoid introducing noisy or low-value features at this stage.\n",
        "\n",
        "The Timings column was lightly cleaned by normalizing spaces while preserving important characters such as time ranges and separators. Instead of fully parsing opening and closing times, two simple operational features were derived: whether a restaurant is open all days of the week (Is_Open_All_Days) and whether it operates 24 hours (Is_24_Hours). This provides useful context for analysis without overcomplicating preprocessing.\n",
        "\n",
        "Overall, the wrangling steps improved consistency in text fields, structured multi-value columns, and added a few meaningful derived features while keeping the preprocessing simple and interpretable for exploratory analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Univariate"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(merged_data['Rating'], edgecolor='black')\n",
        "plt.xlabel(\"Ratings\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Ratings\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_hwLAecqTUvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how ratings are spread across all restaurants ."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most ratings are high (4–5), which shows customers are generally satisfied. Some low ratings exist, showing a few restaurants need improvement."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-rated restaurants can be promoted more. Low-rated ones need improvement, otherwise they may lose customers and affect platform trust."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Univariate"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(merged_data['Cost'], edgecolor='black' , bins=10)\n",
        "plt.xlabel(\"Cost\")\n",
        "plt.ylabel(\"Amount in Rs\")\n",
        "plt.title(\"Distribution of Cost\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "wcgsBqnafcOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand common pricing range of restaurants."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the restaurants fall in the mid-price range while the number of restaurents is less for cheap and expensive ."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helps identify the most common price segment for customers. Restaurants priced far from the common range may need better positioning or offers to attract more customers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#Univariate"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(x = merged_data['Cuisines_Count'].astype(int))\n",
        "plt.xlabel(\"Number of Cuisines per Restaurent\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Cuisines per Restaurant\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RWFSpeyJih8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how many cousines each restaurant offers ."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most restaurants usually offer less number of cuisines (2-4) while few offer more than 4."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with too many cuisines may struggle with consistency. A focused menu can improve quality and customer satisfaction."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Univariate"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_col = merged_data[merged_data['Collections'] != 'Unknown']\n",
        "all_tags = df_col['Collections'].str.split(',')\n",
        "all_tags = all_tags.explode()\n",
        "all_tags = all_tags.str.strip()\n",
        "tag_counts = all_tags.value_counts()\n",
        "top_10_tags = tag_counts.head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=top_10_tags.values, y=top_10_tags.index)\n",
        "plt.xlabel(\"Number of Restaurants\")\n",
        "plt.ylabel(\"Collection Tags\")\n",
        "plt.title(\"Top 10 Collection Tags (Excluding Unknown)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qwybUHE9tvM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the most common restaurant tags used in collections ."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some collection tags appear much more frequently than others, showing the most common ways restaurants are grouped."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popular collection tags can be promoted more to help customers discover restaurants easily. Less common tags may need better visibility or clearer definitions."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Univariate"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "picture_counts = merged_data['Has_Pictures'].value_counts()\n",
        "plt.bar(picture_counts.index.astype(str), picture_counts.values, edgecolor='black')\n",
        "plt.xlabel(\"Restaurants has Pictures (False=0, True=1)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Has Pictures\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "P6oz7rsSvxA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how many restaurants have pictures and those which do not have ."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most restaurants do not have pictures, while a smaller portion have pictures available."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with pictures can attract more customers. Encouraging restaurants to upload pictures can improve user engagement and trust on the platform."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.scatter(x=merged_data['Cost'], y=merged_data['Rating'])\n",
        "plt.xlabel(\"Average Cost of Dining in Restaurant\")\n",
        "plt.ylabel(\"Rating of the Restaurant\")\n",
        "plt.title(\"Cost vs Rating\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yPa12zr71cQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how the restaurants view is affected by the rating ."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no clear strong pattern between cost and rating. Both low-cost and high-cost restaurants can have good or bad ratings."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher price does not guarantee better customer satisfaction. Restaurants should focus on quality and service, not just pricing. Affordable restaurants can also perform well if they deliver good experience.\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_cuisines_count = merged_data.groupby('Cuisines_Count')['Rating'].mean()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=grouped_cuisines_count.index, y=grouped_cuisines_count.values , edgecolor='black')\n",
        "plt.xlabel(\"Number of Cuisines\")\n",
        "plt.ylabel(\"Average Rating\")\n",
        "plt.title(\"Cuisines vs Rating\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WApWwYE84_fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if the number of cuisines offered by a restaurant affects its average rating."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average rating does not change much with the number of cuisines. Restaurants with fewer or more cuisines can both receive good ratings."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Offering more cuisines does not guarantee higher customer satisfaction. Restaurants should focus on quality of food and service rather than increasing menu variety."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_rating_pics = merged_data.groupby('Has_Pictures')['Rating'].mean()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(avg_rating_pics.index.astype(str), avg_rating_pics.values, edgecolor='black')\n",
        "plt.xlabel(\"Has Pictures (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Average Rating\")\n",
        "plt.title(\"Average Rating vs Has Pictures\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gMVY3wFf_NoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare average ratings of restaurants with and without pictures."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with pictures tend to have slightly higher average ratings compared to those without pictures."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encouraging restaurants to upload pictures can improve customer trust and engagement, which may lead to better ratings and more visits."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_hs_pictures = merged_data.groupby('Has_Pictures')['Cost'].mean()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(avg_hs_pictures.index.astype(str),avg_hs_pictures.values, edgecolor='black')\n",
        "plt.ylabel(\"Average of Cost\")\n",
        "plt.xlabel(\"Has Pictures (False=No and True=Yes)\")\n",
        "plt.title(\"Average Cost vs Has Pictures\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "b4u55UB9c18L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To comapare the relation between avg cost and restaurants wiht and without pictures ."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The restaurants with pictures have just little bit high cost but there is not much difference."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The restaurants which have pictures are likely to have more cost , but those restaurants with no pictures should also be encouraged to have pictures for their restaurants ."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_rating = merged_data.groupby('Rating')['Reviewer_Followers'].mean()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.scatterplot(x=grouped_rating.index , y=grouped_rating.values ,  edgecolor='black')\n",
        "plt.ylabel(\"Reviewer_Followers\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.title(\"Rating vs Reviewer_Followers\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yXWgl8fzmwS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if reviewer with more follower give more rating or less ."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no such proper difference between the popular ans un-poplar reviewers as they both give different ratings ."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings can be treated equally regardless of reviewer popularity. However, reviews from popular reviewers can be highlighted for visibility ."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "#Bivariate"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_rating = merged_data.groupby('Rating')['Is_Open_All_Days'].mean()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=grouped_rating.index, y=grouped_rating.values, edgecolor='lightgreen')\n",
        "plt.ylabel(\"Proportion of Restaurants Open All Days\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.title(\"Average Proportion of Restaurants Open All Days by Rating\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "y1LykpM-rJ1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check whether the restaurants open for all days have a good rating or not ."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-rated restaurants tend to to have a good rating while its significantly less for the restaurants with few lower ratings .\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping restaurants open all days can improve customer satisfaction, which may lead to better ratings."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "#Multivariate"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.scatterplot(merged_data , x='Cost' , y='Rating' , hue='Has_Pictures')\n",
        "plt.title(\"Cost vs Rating Based on Has_Pictures\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "Sp9GSawMtC9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare cost and rating based on the restaurants that have with and without pictures .\n"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with pictures tend to have slightly higher average ratings and slightly higher average cost compared to those without pictures."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants that invest in pictures may attract more customers and can position themselves slightly higher in price."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "#Multivariate"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.scatterplot(merged_data , x='Reviewer_Followers', y='Rating', hue='Is_Open_All_Days' , alpha = 1)\n",
        "plt.title(\"Reviewer_Followers vs Rating Based on Is_Open_All_Days\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "TERQAW7FydFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how reviewer followers relate to ratings , and whether being open all days makes any difference or not ."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no pattern between number of followers and rating. Both open-all-days and not-open-all-days restaurants receive mixed ratings."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings are not biased by reviewer popularity or restaurant availability. Being open all days may improve convenience, but it does not alone guarantee higher ratings."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "#Multivariate"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = merged_data[['Rating', 'Cost', 'Reviewer_Followers', 'Is_Open_All_Days','Cuisines_Count','Has_Pictures']]\n",
        "data_for_heatmap = selected_columns.corr()  #made the correlation matrix\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(data_for_heatmap , annot=True ,cmap ='Greens')\n",
        "plt.title(\"Correlation Between Different Features\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "znn4Sxuc1eaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand how multiple features are related to each other ."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings have very weak correlation with cost, reviewer followers, number of cuisines, pictures, and whether the restaurant is open all days. This means ratings are mostly independent of these factors. Cost and number of cuisines show some relation, meaning restaurants with more cuisines tend to be slightly more expensive."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "#Multivariate"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = merged_data[['Rating', 'Cost', 'Reviewer_Followers', 'Cuisines_Count']]\n",
        "data_for_pairplot = selected_columns.corr()  #made the correlation matrix\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.pairplot(vars=data_for_pairplot , data= merged_data , hue='Has_Pictures')\n",
        "plt.title(\"Correlation Between Different Features\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U5Hy1o874-2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To observe relationships between multiple numerical features at once and see how they differ based on whether restaurants have pictures."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no strong visible relationship between ratings and cost or reviewer followers. Restaurants with pictures and without pictures are spread similarly across most feature combinations, with only slight differences in distribution."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do restaurants with pictures get higher ratings?\n",
        "* H0 (Null): There is no significant difference in average ratings between restaurants with pictures and without pictures.\n",
        "* H1 (Alternate): Restaurants with pictures have significantly different (higher) average ratings than those without pictures."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "with_pics = merged_data[merged_data['Has_Pictures'] == 1]['Rating']\n",
        "without_pics = merged_data[merged_data['Has_Pictures'] == 0]['Rating']\n",
        "\n",
        "t_stat, p_val = ttest_ind(with_pics, without_pics, equal_var=False)\n",
        "t_stat, p_val"
      ],
      "metadata": {
        "id": "V55C-OdLOYp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent two-sample t-test ."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test compares the means of two independent groups (restaurants with pictures vs without pictures) to check if their average ratings are significantly different."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Is higher cost associated with higher rating?\n",
        "\n",
        "* H0: There is no significant correlation between restaurant cost and rating.\n",
        "* H1: There is a significant correlation between restaurant cost and rating."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "corr, p_val = pearsonr(merged_data['Cost'], merged_data['Rating'])\n",
        "corr, p_val"
      ],
      "metadata": {
        "id": "uQY3mgR3PdwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation test ."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation measures the strength and direction of linear relationship between two continuous variables (cost and rating)."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do 24-hour open restaurants get different ratings compared to non-24-hour ones?\n",
        "\n",
        "* H0: There is no significant difference in average ratings between 24-hour open restaurants and others.\n",
        "* H1: There is a significant difference in average ratings between 24-hour open restaurants and others."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "open_24 = merged_data[merged_data['Is_24_Hours'] == 1]['Rating']\n",
        "not_open_24 = merged_data[merged_data['Is_24_Hours'] == 0]['Rating']\n",
        "\n",
        "t_stat, p_val = ttest_ind(open_24, not_open_24, equal_var=False)\n",
        "t_stat, p_val"
      ],
      "metadata": {
        "id": "6AloDHMuQJZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent two-sample t-test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test compares average ratings of two independent groups to check whether operating 24 hours has a statistically significant effect on ratings."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#re-checking and ensuring no missing values remain\n",
        "merged_data['Review'] = merged_data['Review'].fillna('')   #the review is filled with empty string to avoid false prediction of reviews which would give wrong impact if read wrongly during tokenization\n",
        "merged_data['Rating'] = merged_data['Rating'].fillna(merged_data['Rating'].median())\n",
        "merged_data['Cost'] = merged_data['Cost'].fillna(merged_data['Cost'].median())\n",
        "merged_data['Reviewer_Review_Count'] = merged_data['Reviewer_Review_Count'].fillna(merged_data['Reviewer_Review_Count'].median())\n",
        "merged_data['Reviewer_Followers'] = merged_data['Reviewer_Followers'].fillna(merged_data['Reviewer_Followers'].median())\n",
        "merged_data['Collections'] = merged_data['Collections'].fillna('Unknown')\n",
        "merged_data['Timings'] = merged_data['Timings'].fillna('Not Available')\n",
        "merged_data['Cuisines_Count'] = merged_data['Cuisines_Count'].fillna(merged_data['Cuisines_Count'].median())\n",
        "\n",
        "#Is_Open_All_Days & Is_24_Hours is handled explicitly and hence all rows are properly filled ."
      ],
      "metadata": {
        "id": "O_JFZidJ0hHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this indicates that there are no more missing values in the dataframe as we have replaced those  values depending on their col values .\n",
        "merged_data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CCJ4U6Qc0XPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below are the actual rows which are filled using null values .\n",
        "* Review\t9\n",
        "* Rating\t3\n",
        "* Time\t2\n",
        "* Cost\t3686\n",
        "* Collections\t5000\n",
        "* Timings\t100\n",
        "\n",
        "The below modifications were made in the respective columns .\n",
        "\n",
        "* Text columns (Review) is filled with empty strings.\n",
        "* Numerical columns (Rating, Cost) were imputed using median to reduce the impact of outliers.\n",
        "* Categorical columns (Collections, Timings) were filled with meaningful placeholders like “Unknown” or “Not Available”.\n",
        "\n",
        "#### Review column is the most important column is the df hence the null values were filled with empty string because directly writing false reviews or even good reviews can have a small impact on the model .\n",
        "#### Numerical values were filled with median which was the most appropriate and the best way as cost had almost 35% missing data .\n",
        "#### Collections was the most wierd column as it had 50% of missing values which were placed with suitable placeholders and the same with timings col .\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting of Columns Before Removing Outliers"
      ],
      "metadata": {
        "id": "crA5lg2OG5gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#these columns are selected bcoz there is high chance of outliers being in this data and also as the data is numerical so it will definitely work .\n",
        "#we need not check outliers for Text columns , Booleans , Categorical strings , Time\n",
        "\n",
        "cols = ['Rating', 'Reviewer_Review_Count', 'Reviewer_Followers', 'Cost', 'Cuisines_Count']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, col in enumerate(cols, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    plt.hist(merged_data[col], bins=30)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "84LMZxZU7wJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the IQR technique for each col ( explaination is below in text cell)\n",
        "#find the 25th and 75th percentile for each columns\n",
        "#for this we can either use the .describe() funtn on each column or the .quantile() funtion to get the 25th Percentile and 75th percentile"
      ],
      "metadata": {
        "id": "JsavmbNnHfJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loop for the IQR method\n",
        "for col in ['Rating', 'Reviewer_Review_Count', 'Reviewer_Followers', 'Cost', 'Cuisines_Count']:\n",
        "    Q1 = merged_data[col].quantile(0.25)\n",
        "    Q3 = merged_data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_limit = Q1 - 1.5 * IQR\n",
        "    upper_limit = Q3 + 1.5 * IQR\n",
        "\n",
        "    merged_data[col] = np.where(merged_data[col] > upper_limit, upper_limit,\n",
        "                                np.where(merged_data[col] < lower_limit, lower_limit, merged_data[col]))\n"
      ],
      "metadata": {
        "id": "-heGam0DYFwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting of Columns After Removing Outliers"
      ],
      "metadata": {
        "id": "0nCyNikATcuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Rating', 'Reviewer_Review_Count', 'Reviewer_Followers', 'Cost', 'Cuisines_Count']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, col in enumerate(cols, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    plt.hist(merged_data[col], bins=30)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tsMshVLaTQN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The graphs which I plotted before are given above which indicate a good number of outliers in the mentioned 5 cols .\n",
        "2.  There was not specific normal distribution among the plots and all the plots were either right or left skewed hence the technique of Z-score to find outliers was not efficient .\n",
        "3.  Due to this we use the IQR ( Interquantile Range ) technique to find the outliers and handle them.\n",
        "4.  Also instead of trimming the outliers we used capping them to preserve the data consistency .\n",
        "5. In this technique we first found the 25 & 75 percentile value of the col which resulted to find the iqr of cols and with the help of iqr we were able to efficiently find the upper & lower limit of the cols .\n",
        "6.  The outliers were then adjusted with the upper & lower limit and hence the outliers are now handled .\n",
        "7. After applying IQR-based capping, the distributions became less skewed and extreme values were reduced. This helps prevent outliers from dominating model training while retaining all observations."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converted the boolean True/False to proper int format 1/0\n",
        "cols_to_int = ['Is_Open_All_Days','Is_24_Hours','Has_Pictures','Cuisines_Count','Reviewer_Review_Count','Reviewer_Followers']\n",
        "merged_data[cols_to_int] = merged_data[cols_to_int].astype(int)"
      ],
      "metadata": {
        "id": "LHdC6EKPYsCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Info in these columns is not very helpful and is too much heavy as there is only one hot coding applicable .\n",
        "cols_to_drop = ['Collections', 'Timings']\n",
        "merged_data = merged_data.drop(columns=cols_to_drop)"
      ],
      "metadata": {
        "id": "K6kQPmonYrn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The Timings column contains unstructured textual information about restaurant operating hours, which is difficult to reliably encode into numerical features and may introduce noise. Instead, structured temporal features extracted from the Time column were used.\n",
        "* The Collections column has high cardinality and sparse categorical values bcoz it may get splitted into 50-100 more columns , which can lead to high-dimensional feature space and overfitting when encoded. Therefore, it was excluded to maintain a compact and interpretable feature set for modeling.\n"
      ],
      "metadata": {
        "id": "7bp1cWCBdGQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. According to me there was no such need to use the categorical encoding .\n",
        "2. Data types of some columns was change from bool/float to proper integers wherever reuired .\n",
        "3. Ordinal encoding was not possible because of the data ; but there was a chance to use the one hot encoding .\n",
        "4. But the reason we decided to drop the columns like Timings & Collections was that if we would have applied the one hot encoding on these columns then too many colmns would have been generated (around 50+) which was very heavy data to handle and not required as such .\n",
        "5. The information in these 2 columns was not that useful to make seperate cols and make more traffic , hence we removed these rows .\n",
        "6. The Cuisines col was dropped bcox we had made a new col Cuisines_Count which was sufficient for handing the impoertance of that column .\n",
        "\n"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contractions in review text were expanded (e.g. 'don’t' to 'do not') to standardize language.\n",
        "merged_data['Review'] = merged_data['Review'].apply(contractions.fix)"
      ],
      "metadata": {
        "id": "yj8Rxf63oAey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the case of review col to lowercase .\n",
        "merged_data['Review'] = merged_data['Review'].str.lower()"
      ],
      "metadata": {
        "id": "gZF4_yH0sQ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the unnecessary punctuation and special characters from the review col text using regex expression\n",
        "merged_data['Review'] = merged_data['Review'].str.replace(r'[^\\w\\s]', ' ', regex=True)"
      ],
      "metadata": {
        "id": "oVu_CYPeti2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the links inside strings of review col\n",
        "merged_data['Review'] = merged_data['Review'].str.replace(r'https?://\\S+|www\\.\\S+', '', regex=True)"
      ],
      "metadata": {
        "id": "JPUg2nthw__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the texts which include digits in them\n",
        "merged_data['Review'] = merged_data['Review'].str.replace(r'\\b\\w*\\d\\w*\\b', '', regex=True)"
      ],
      "metadata": {
        "id": "KrqVi9oXygjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the stopwords present in the texts\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "cwCOa-SjzGhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "\n",
        "    words = text.split()         #split into indiviadual words\n",
        "    filtered_words = [word for word in words if word not in stop_words]       #removed stopwords\n",
        "    cleaned_text = \" \".join(filtered_words)          #join back to sentence\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vrnl_awk1WS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data['Review'] = merged_data['Review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "4ZXWjsue8Zsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removes the trailing , leading and in between spaces from the texts and replaces it with just one space\n",
        "merged_data['Review'] = merged_data['Review'].str.replace(r'\\s+', ' ', regex=True).str.strip()"
      ],
      "metadata": {
        "id": "NqBfRntizHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### By reviewing some of the columns in the review ; i fount that there are not many rows which have slang abbreviations , so it is better to let it remain as it is and not do any implementation for this col ."
      ],
      "metadata": {
        "id": "k7ITgL7wBhKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    text = str(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "merged_data['Review_Tokens'] = merged_data['Review'].apply(tokenizer)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JmUKbtGDB6jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_order = ['Restaurant','Rating','Review','Review_Tokens','Cost','Cuisines_Count','Has_Pictures',\n",
        "    'Is_Open_All_Days','Is_24_Hours','Time','Reviewer_Review_Count','Reviewer_Followers'\n",
        "]\n",
        "\n",
        "merged_data = merged_data[new_order]"
      ],
      "metadata": {
        "id": "pb8om2pgFyq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer(tokens):\n",
        "    tokens = list(tokens)\n",
        "    lemmatized_words = [lemma.lemmatize(word) for word in tokens]\n",
        "    return lemmatized_words\n",
        "\n",
        "merged_data['Review_Lemmas'] = merged_data['Review_Tokens'].apply(lemmatizer)"
      ],
      "metadata": {
        "id": "PFsboPm9J9Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_order = ['Restaurant','Rating','Review','Review_Tokens','Review_Lemmas','Cost','Cuisines_Count','Has_Pictures',\n",
        "    'Is_Open_All_Days','Is_24_Hours','Time','Reviewer_Review_Count','Reviewer_Followers'\n",
        "]\n",
        "\n",
        "merged_data = merged_data[new_order]"
      ],
      "metadata": {
        "id": "SD7NZtclLmp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lemmatization was used for text normalization as it converts words to their meaningful base forms (e.g. eating -> eat), preserving semantic meaning and improving consistency for feature extraction in NLP models."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tokens = merged_data['Review_Tokens'].head(5)\n",
        "merged_data['Review_POS_Sample'] = sample_tokens.apply(pos_tag)\n",
        "merged_data[['Review_Tokens', 'Review_POS_Sample']].head(5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MbHLdMLaOWUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Ul-wO9yrSEry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new col for sentiment analysis by converting rating to its categorical part .\n",
        "def create_sentiment(rating):\n",
        "    if rating >= 4.0:\n",
        "        return 2  #positive\n",
        "    elif rating <= 2.0:\n",
        "        return 0  #negative\n",
        "    else:\n",
        "        return 1  #neutral\n",
        "\n",
        "merged_data['Sentiment'] = merged_data['Rating'].apply(create_sentiment)"
      ],
      "metadata": {
        "id": "hlN4xARdeacB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def tokens_to_text(token_string):\n",
        "    try:\n",
        "        tokens = ast.literal_eval(token_string)           #convert string representation of list to actual list for better analysis\n",
        "        return ' '.join(tokens)         #join tokens with spaces\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "merged_data['Review_Text'] = merged_data['Review'].apply(tokens_to_text)"
      ],
      "metadata": {
        "id": "ArNgSmxrfewT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data['Review_Text'] = merged_data['Review']\n",
        "\n",
        "x_text = merged_data['Review_Text']\n",
        "y = merged_data['Sentiment']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_text, y, test_size=0.2, random_state=42 , stratify=y)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1,2), min_df=5)\n",
        "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
        "x_test_tfidf = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "YWF-jZDOUB4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfidf.shape , x_test_tfidf.shape"
      ],
      "metadata": {
        "id": "24Zzr_RbUByT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF(Term Frequency–Inverse Document Frequency) was used because it converts text into meaningful numerical features and emphasizes informative words over commonly occurring ones."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting features from Time col\n",
        "merged_data['Review_Year'] = merged_data['Time'].dt.year\n",
        "merged_data['Review_Month'] = merged_data['Time'].dt.month\n",
        "merged_data['Review_DayOfWeek'] = merged_data['Time'].dt.dayofweek\n",
        "merged_data['Review_Hour'] = merged_data['Time'].dt.hour\n",
        "\n",
        "#review length uning review_tokens col\n",
        "merged_data['Review_Length'] = merged_data['Review_Tokens'].apply(len)"
      ],
      "metadata": {
        "id": "iuurz5ZVTKkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the less important or redundant columns from the df .\n",
        "merged_data = merged_data.drop(columns=['Review_Tokens','Review_Lemmas','Time','Review_POS_Sample'])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "85oksA7Rd12S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection was performed using domain knowledge and correlation-based filtering.\n",
        "* Non-informative columns (e.g.raw timestamp, demo-only POS tags) were removed.\n",
        "* Redundant raw text features were excluded after TF-IDF vectorization to avoid data leakage and reduce dimensionality.\n",
        "> This manual, knowledge basis selection helps reduce overfitting and improves model generalization across multiple ML models."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The most important features include Cost, Cuisines_Count, Has_Pictures, Is_Open_All_Days, Is_24_Hours, Reviewer_Review_Count, Reviewer_Followers, and temporal features (review year, month, day of week, hour).\n",
        "2. These features indicate pricing, menu diversity, content richness, restaurant availability, reviewer activity, and time-based patterns, all of which are intuitively related to customer ratings and behavior.\n",
        "3. Additionally, TF-IDF text features from reviews were retained as they capture sentiment and contextual cues from user feedback."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying logarithmic transfromations\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ],
      "metadata": {
        "id": "oe4YLrlOhaCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trf = FunctionTransformer(np.log1p, validate=False)\n",
        "cols = ['Cost', 'Reviewer_Review_Count', 'Reviewer_Followers','Review_Length']\n",
        "merged_data[cols] = trf.fit_transform(merged_data[cols])"
      ],
      "metadata": {
        "id": "Tg_DopuGhZ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes the data needs to be tranformed before doing training or testing on the data to improve the normal distribution .\n",
        "* Log transformation was preferred over Yeo–Johnson,Box-Cox or other function transformer because it was efficient to handle the values of skewed numerical features as the variables were non-negative and exhibited right-skewness typically for cost .\n",
        "* Log transform offers simplicity, interpretability, and sufficient normalization .\n",
        "* Although Yeo–Johnson can handle a wider range of distributions, log transformation was chosen for its interpretability and suitability for non-negative skewed variables in this dataset."
      ],
      "metadata": {
        "id": "LEQhNlo5rAJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack"
      ],
      "metadata": {
        "id": "Jcs3O4wTsgjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = ['Cost', 'Cuisines_Count', 'Reviewer_Review_Count', 'Reviewer_Followers',\n",
        "    'Review_Year', 'Review_Month', 'Review_DayOfWeek', 'Review_Hour', 'Review_Length'\n",
        "]\n",
        "\n",
        "#extract numeric features from merged_data\n",
        "X_numerical = merged_data[num_cols]\n",
        "\n",
        "#align numeric features with train/test indices\n",
        "X_numerical_train = X_numerical.loc[y_train.index]\n",
        "X_numerical_test = X_numerical.loc[y_test.index]\n",
        "\n",
        "#scale numeric features (fit & transform train, transform test)\n",
        "scaler = StandardScaler()\n",
        "X_numerical_train_scaled = scaler.fit_transform(X_numerical_train)\n",
        "X_numerical_test_scaled = scaler.transform(X_numerical_test)\n",
        "\n",
        "#combine TF-IDF with scaled numeric features\n",
        "X_train_final = hstack([x_train_tfidf, X_numerical_train_scaled])\n",
        "X_test_final = hstack([x_test_tfidf, X_numerical_test_scaled])\n",
        "\n",
        "print(X_train_final.shape, X_test_final.shape)"
      ],
      "metadata": {
        "id": "PhhoqUYbsgc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization was preferred over Normalization as it centers features to zero mean and 1 variance, making it more suitable for linear and distance-based models used in this study.\n",
        "* Min–Max normalization can be overly sensitive to extreme values present in cost and reviewer metrics.\n",
        "* Also in this case there is no such strict constraint to make values in the range of [0,1] , it is better to keep the data in cols little diverse rather than contracting it to a specific range ."
      ],
      "metadata": {
        "id": "TwCvDkCDshsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction is not strictly required, but TF-IDF creates a very large number of features. Reducing dimensions helps remove noise, speeds up model training, and can improve performance for clustering and distance-based models. Hence, dimensionality reduction was explored as an optimization step."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=200, random_state=42)\n",
        "\n",
        "x_train_tfidf_svd = svd.fit_transform(x_train_tfidf)\n",
        "x_test_tfidf_svd = svd.transform(x_test_tfidf)\n",
        "\n",
        "print(\"Before:\", x_train_tfidf.shape)\n",
        "print(\"After :\", x_train_tfidf_svd.shape)\n",
        "print(\"Explained variance:\", svd.explained_variance_ratio_.sum())\n"
      ],
      "metadata": {
        "id": "rIJ9T7eiEIE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TruncatedSVD was used because it works well with sparse TF-IDF data and reduces thousands of text features into a smaller number of meaningful components while keeping most of the important information."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_text, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "U1mcXyafFKhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The dataset was split into training and testing sets using an 80:20 ratio to evaluate model performance on unseen data.\n",
        "2. Splitting was performed before model training and feature scaling to avoid data leakage and ensure fair evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the dataset is slightly imbalanced.\n",
        "After converting ratings into High(≥4) and Low(<4) around 63% of the samples belong to the high-rating class and about 37% belong to the low-rating class. This shows a mild imbalance, which is common in review datasets where positive reviews are more frequent than negative ones."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_binary = (merged_data['Rating'] >= 4).astype(int)\n",
        "rating_binary.value_counts(normalize=True) * 100\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ECediJ06L7n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just converted the datatypes to proper\n",
        "cols_to_int = ['Review_Length','Reviewer_Followers','Reviewer_Review_Count']\n",
        "merged_data[cols_to_int] = merged_data[cols_to_int].astype(int)"
      ],
      "metadata": {
        "id": "NENt39USPXn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No such special technique was used .\n",
        "> Since the imbalance is mild (63% vs 37%), the original data distribution was kept. During model training, class weighting can be used to reduce bias toward the majority class without creating artificial data. This keeps the model learning realistic patterns from real reviews."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ML Model 1: Logistic Regression for Sentiment Analysis\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = merged_data['Review_Text']\n",
        "y = merged_data['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#converted text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "#fiting the algo\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "#predicting the value\n",
        "y_pred = model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "4t9c9hO7qXYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model performance using evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n\" + classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm);"
      ],
      "metadata": {
        "id": "vtEiAiR95YJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "\n",
        "#cross-validation\n",
        "cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=5)\n",
        "print(f\"CV Scores: {cv_scores}\")\n",
        "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
        "\n",
        "#hyperparameter tuning\n",
        "param_grid = {'C': [0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=500), param_grid, cv=3)\n",
        "grid.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid.best_params_}\")\n",
        "print(f\"Best CV Score: {grid.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "dlk2E7x-SE5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV to find the best value of C (regularization parameter). It tests different values using cross-validation and selects the best one."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "y_pred_tuned = best_model.predict(X_test_tfidf)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "#comparison Chart\n",
        "x = ['Baseline', 'Tuned']\n",
        "y = [accuracy, accuracy_tuned]\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(x, y, color=['lightblue', 'lightgreen'])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "for i, v in enumerate(y):\n",
        "    plt.text(i, v + 0.02, f'{v:.4f}', ha='center')\n",
        "plt.show();"
      ],
      "metadata": {
        "collapsed": true,
        "id": "07xqDaBDTBxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can see that there is no such specific improvenent in the models performance but the good thing is that there is no decline in the accuracy too . So its a good sign for the model as after hyperparameter optimization the accuracy increased by ~1 ."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model 2: Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#fitting the algo\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "MPsn8lLrUNDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model Performance using evaluation metric score chart\n",
        "\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(f\"Accuracy: {acc_rf:.4f}\")\n",
        "print(\"\\n\" + classification_report(y_test, y_pred_rf, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "#confusion matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "owdPaG72Uihr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores_rf = cross_val_score(rf_model, X_train_tfidf, y_train, cv=5)\n",
        "print(f\"CV Scores: {cv_scores_rf}\")\n",
        "print(f\"Mean CV Score: {cv_scores_rf.mean():.4f}\")\n",
        "\n",
        "#hyperparameter tuning\n",
        "param_grid_rf = {'n_estimators': [50, 100], 'max_depth': [10, 20]}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3)\n",
        "grid_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid_rf.best_params_}\")\n",
        "print(f\"Best CV Score: {grid_rf.best_score_:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HX6aFviZVvOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV to optimize n_estimators and max_depth for better accuracy."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf_tuned = best_rf.predict(X_test_tfidf)\n",
        "acc_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)\n",
        "\n",
        "print(\"Before vs After Tuning:\")\n",
        "print(f\"Baseline: {acc_rf:.4f}\")\n",
        "print(f\"Tuned: {acc_rf_tuned:.4f}\")\n",
        "print(f\"Improvement: {acc_rf_tuned - acc_rf:+.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "csy5iHtQYnIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There was no significant increase in the model after tuning . Hence this model cannot be concluded as a good model for our performance analysis .\n",
        "\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Can be used alongside Logistic Regression for ensemble predictions .\n",
        "* Better but not that much at handling complex review patterns."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model 3: K-Means Clustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Prepare restaurant-level data\n",
        "restaurant_data = merged_data.groupby('Restaurant').agg({\n",
        "    'Cost': 'mean',\n",
        "    'Rating': 'mean',\n",
        "    'Cuisines_Count': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "#features selection and scaling\n",
        "X_cluster = restaurant_data[['Cost', 'Rating', 'Cuisines_Count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "#fitted 4-clusters\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "restaurant_data['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "print(\"Cluster distribution:\")\n",
        "print(restaurant_data['Cluster'].value_counts().sort_index())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DXh79F79aO6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "sil_score = silhouette_score(X_scaled, restaurant_data['Cluster'])\n",
        "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
        "\n",
        "# Cluster summary\n",
        "print(\"\\nCluster Characteristics:\")\n",
        "print(restaurant_data.groupby('Cluster')[['Cost', 'Rating', 'Cuisines_Count']].mean())\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(7, 5))\n",
        "scatter = plt.scatter(restaurant_data['Cost'], restaurant_data['Rating'],\n",
        "                     c=restaurant_data['Cluster'], cmap='viridis', s=80)\n",
        "plt.xlabel('Average Cost')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Restaurant Clusters')\n",
        "plt.colorbar(scatter, label='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gsclApZEbtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inertias = []\n",
        "sil_scores = []\n",
        "\n",
        "for k in range(2, 8):\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    km.fit(X_scaled)\n",
        "    inertias.append(km.inertia_)\n",
        "    sil_scores.append(silhouette_score(X_scaled, km.labels_))\n",
        "\n",
        "print(f\"Best K: {range(2, 8)[np.argmax(sil_scores)]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aNo5bnOXb_sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_k = range(2, 8)[np.argmax(sil_scores)]\n",
        "kmeans_opt = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "restaurant_data['Cluster_Opt'] = kmeans_opt.fit_predict(X_scaled)\n",
        "\n",
        "sil_opt = silhouette_score(X_scaled, restaurant_data['Cluster_Opt'])\n",
        "\n",
        "print(f\"Original (K=4): {sil_score:.4f}\")\n",
        "print(f\"Optimal (K={optimal_k}): {sil_opt:.4f}\")\n",
        "print(f\"Improvement: {sil_opt - sil_score:+.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hh2D-ASmdloY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used with K-Means clustering to automate the search for optimal hyperparameters, such as the number of clusters , initialization methods, and maximum iterations."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using optimal K improved silhouette score, creating better-defined restaurant segments for business analysis."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I considered four main metrics:\n",
        "1. Accuracy - Shows overall correctness of predictions. Higher accuracy means the model can automate more reviews correctly, saving time and reducing manual work.\n",
        "2. Precision - Important because it reduces false alarms.High precision means restaurant owners get accurate alerts and don't waste time on false positives.\n",
        "3. Recall - Critical for catching all negative reviews. If we miss customer complaints , unhappy customers might not get responses, hurting business reputation. High recall ensures we don't miss important feedback.\n",
        "4. F1-Score - Balances precision and recall. It gives a single number to track overall model quality, making it easier to monitor performance over time.\n",
        "\n",
        "These metrics together help ensure the model is reliable for real-world use, where both accuracy and catching all complaints matter."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model which was trained using Logistic Regression for Sentiment analysis was the best model as its accuracy was consistent on the provided data which indicates that the model would also work for large dataset .\n",
        "1. Good Accuracy - It achieved around 80-85% accuracy, which is reliable for sentiment classification.\n",
        "2. Consistent Performance - The cross-validation scores were stable, showing the model works consistently on different data subsets.\n",
        "3. Simple and Fast - Logistic Regression is easy to understand and runs quickly, making it suitable for processing large numbers of reviews in real-time."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a classification algorithm that learns which words in reviews indicate positive, negative, or neutral sentiment. It works by:\n",
        "\n",
        "Converting review text into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency) and assigning weights to different words based on their importance & combining these weights to predict the sentiment category .\n",
        "\n",
        "Feature Importance:\n",
        "I analyzed which words are most important for predictions:\n",
        "\n",
        "* For Negative Sentiment:\n",
        "Words like \"bad\", \"worst\", \"terrible\", \"poor service\" have high negative weights.\n",
        "These words strongly indicate customer dissatisfaction\n",
        "\n",
        "* For Positive Sentiment:\n",
        "Words like \"excellent\", \"amazing\", \"great food\", \"loved\" have high positive weights\n",
        "These indicate customer satisfaction\n",
        "\n",
        "* For Neutral Sentiment:\n",
        "Words like \"okay\", \"average\", \"decent\" fall in the middle\n",
        "\n",
        "\n",
        "Understanding feature importance helps:\n",
        "1. Identify what customers complain about most .(e.g.\"slow service\", \"cold food\")\n",
        "2. Recognize what makes customers happy. (e.g., \"friendly staff\", \"delicious\")"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, the Zomato dataset was successfully cleaned, explored, and analyzed to understand customer behavior and restaurant characteristics.\n",
        "Several visualizations were created to identify patterns between ratings, cost, cuisines, and customer reviews.\n",
        "> Restaurants were grouped into different segments using clustering, and customer sentiments were analyzed from review text.\n",
        "\n",
        "> The results show that factors such as pricing, cuisines offered, and customer engagement play an important role in restaurant popularity and customer satisfaction.\n",
        "\n",
        "> These insights can help customers make better dining choices and help the business improve its recommendation strategies and overall service quality."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}